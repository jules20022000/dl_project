{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of recordings:  6661\n",
      "Number of features:  13\n"
     ]
    }
   ],
   "source": [
    "record_df = pd.read_csv(\"./data/overview-of-recordings.csv\")\n",
    "\n",
    "# print the number of recordings\n",
    "print(\"Number of recordings: \", len(record_df))\n",
    "print(\"Number of features: \", len(record_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  381\n",
      "Number of test samples:  5895\n",
      "Number of validation samples:  385\n",
      "Total number of samples:  6661\n"
     ]
    }
   ],
   "source": [
    "# check if we have the same number of audio files (.wav) as we have rows in the dataframe\n",
    "data_dir = \"./data/recordings\"\n",
    "nb_training_samples = len(os.listdir(os.path.join(data_dir, \"train\")))\n",
    "nb_test_samples = len(os.listdir(os.path.join(data_dir, \"test\")))\n",
    "nb_validation_samples = len(os.listdir(os.path.join(data_dir, \"validate\")))\n",
    "print(\"Number of training samples: \", nb_training_samples)\n",
    "print(\"Number of test samples: \", nb_test_samples)\n",
    "print(\"Number of validation samples: \", nb_validation_samples)\n",
    "print(\"Total number of samples: \", nb_training_samples + nb_test_samples + nb_validation_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt\n",
       "Acne                  328\n",
       "Shoulder pain         320\n",
       "Joint pain            318\n",
       "Infected wound        306\n",
       "Knee pain             305\n",
       "Cough                 293\n",
       "Feeling dizzy         283\n",
       "Muscle pain           282\n",
       "Heart hurts           273\n",
       "Ear ache              270\n",
       "Hair falling out      264\n",
       "Head ache             263\n",
       "Feeling cold          263\n",
       "Skin issue            262\n",
       "Stomach ache          261\n",
       "Back pain             259\n",
       "Neck pain             251\n",
       "Internal pain         248\n",
       "Blurry vision         246\n",
       "Body feels weak       241\n",
       "Hard to breath        233\n",
       "Emotional pain        231\n",
       "Injury from sports    230\n",
       "Foot ache             223\n",
       "Open wound            208\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_df.prompt.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different speakers: 124\n",
      "Number of different writers: 45\n"
     ]
    }
   ],
   "source": [
    "# print the number of different speakers\n",
    "print(f\"Number of different speakers: {len(record_df.speaker_id.unique())}\")\n",
    "\n",
    "# print the number of different writer \n",
    "print(f\"Number of different writers: {len(record_df.writer_id.unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the audio data with the metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:00<00:00, 571.39it/s]\n"
     ]
    }
   ],
   "source": [
    "train_path = \"./data/recordings/train\"\n",
    "for file in tqdm(os.listdir(train_path)):\n",
    "    waveform, sample_rate = torchaudio.load(os.path.join(train_path, file))\n",
    "    metadata = record_df[record_df[\"file_name\"] == file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First idea : analyze the waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second idea : Use the phrase from the metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare both \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a combination of both\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
