{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice-Driven Disease Classification: A Deep Learning Approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "from model.classifier import Classifier\n",
    "from model.conv_net import M5\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_df = pd.read_csv(\"./data/overview-of-recordings.csv\")\n",
    "\n",
    "# print the number of recordings\n",
    "print(\"Number of recordings: \", len(record_df))\n",
    "print(\"Number of features: \", len(record_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we have the same number of audio files (.wav) as we have rows in the dataframe\n",
    "data_dir = \"./data/recordings\"\n",
    "nb_training_samples = len(os.listdir(os.path.join(data_dir, \"train\")))\n",
    "nb_validation_samples = len(os.listdir(os.path.join(data_dir, \"validate\")))\n",
    "nb_test_samples = len(os.listdir(os.path.join(data_dir, \"test\")))\n",
    "print(\"Number of training samples: \", nb_training_samples)\n",
    "print(\"Number of validation samples: \", nb_validation_samples)\n",
    "print(\"Number of test samples: \", nb_test_samples)\n",
    "print(\"Total number of samples: \", nb_training_samples + nb_test_samples + nb_validation_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a column to indicate if the record is in the training set, validation set, or test set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = set(os.listdir(os.path.join(data_dir, \"train\")))\n",
    "valid_files = set(os.listdir(os.path.join(data_dir, \"validate\")))\n",
    "test_files = set(os.listdir(os.path.join(data_dir, \"test\")))\n",
    "\n",
    "record_df[\"split\"] = record_df[\"file_name\"].apply(lambda x: \"train\" if x in train_files else (\"validate\" if x in valid_files else \"test\"))\n",
    "\n",
    "# check if the numbers corresponds to the previous numbers\n",
    "print(\"Number of training samples: \", len(record_df[record_df.split == \"train\"]))\n",
    "print(\"Number of validation samples: \", len(record_df[record_df.split == \"validate\"]))\n",
    "print(\"Number of test samples: \", len(record_df[record_df.split == \"test\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for each split\n",
    "train_df = record_df[record_df['split'] == 'train']\n",
    "valid_df = record_df[record_df['split'] == 'validate']\n",
    "test_df = record_df[record_df['split'] == 'test']\n",
    "\n",
    "# Create Seaborn count plot\n",
    "def create_count_plot(ax, df, title, color):\n",
    "    sns.countplot(y='prompt', data=df, color=color, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_ylabel('Prompt')\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # Adjust the figure size as needed\n",
    "\n",
    "# Combine the count plots on the same row\n",
    "create_count_plot(axes[0], train_df, 'Training Set', 'blue')\n",
    "create_count_plot(axes[1], valid_df, 'Validation Set', 'green')\n",
    "create_count_plot(axes[2], test_df, 'Test Set', 'red')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionnary to map each prompt to a number\n",
    "prompt_to_id = {prompt: i for i, prompt in enumerate(record_df.prompt.unique())}\n",
    "prompt_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column label from the prompt column\n",
    "record_df[\"label\"] = record_df[\"prompt\"].apply(lambda x: prompt_to_id[x])\n",
    "\n",
    "record_df.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification using directly the transformer and not the embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(prompt_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = record_df[record_df['split'] == 'train']\n",
    "valid_df = record_df[record_df['split'] == 'validate']\n",
    "test_df = record_df[record_df['split'] == 'test']\n",
    "\n",
    "print(\"Number of training samples: \", len(train_df))\n",
    "print(\"Number of validation samples: \", len(valid_df))\n",
    "print(\"Number of test samples: \", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_df['phrase']), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(list(valid_df['phrase']), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(test_df['phrase']), truncation=True, padding=True)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']), torch.tensor(train_encodings['attention_mask']), torch.tensor(train_df['label'].values))\n",
    "val_dataset = TensorDataset(torch.tensor(val_encodings['input_ids']), torch.tensor(val_encodings['attention_mask']), torch.tensor(valid_df['label'].values))\n",
    "test_dataset = TensorDataset(torch.tensor(test_encodings['input_ids']), torch.tensor(test_encodings['attention_mask']), torch.tensor(test_df['label'].values))\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# !!NOTE!!: Use the test as train and train + validate to test\n",
    "train_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Set up training parameters\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Tr. Loss:  {loss.item()}', end='\\r')\n",
    "        \n",
    "        \n",
    "    # Evaluation on the validation set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += len(labels)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch: {epoch + 1}, Tr. Loss:  {loss.item()}, Val. Accuracy: {accuracy}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a trained model stored in the variable 'model'\n",
    "model.eval()\n",
    "\n",
    "# New text for prediction\n",
    "new_text = \"I'm sad when I think of you.\"\n",
    "\n",
    "# Tokenize the new text\n",
    "new_text_encoding = tokenizer(new_text, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Make the prediction\n",
    "with torch.no_grad():\n",
    "    output = model(**new_text_encoding)\n",
    "\n",
    "# Get the predicted class\n",
    "predicted_class = torch.argmax(output.logits).item()\n",
    "\n",
    "print(f\"Predicted class:  {list(prompt_to_id.keys())[predicted_class]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second idea : Use the phrase from the metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a pre trained transformer model to get the embeddings of the phrase \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save the embeddings for the phrases in the metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_embedd = \"./data/embeddings\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in tqdm(record_df.iterrows(), total=len(record_df)):\n",
    "    # save path for the embedding\n",
    "    save_path = os.path.join(save_path_embedd, row.split, row.file_name.replace(\".wav\", \".pt\"))\n",
    "    sentence = row.phrase\n",
    "    tokenized_text = tokenizer.tokenize(sentence)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    model.eval()\n",
    "    # Get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    # take the mean of the embeddings over the whole sentence\n",
    "    sentence_embedding = torch.mean(hidden_states[0], dim=0)\n",
    "    \n",
    "    # !! NOTE: we add the label at the end of the embedding (hence 768 for the embedding size and 1 for the label)\n",
    "    sentence_embedding_with_label = torch.cat((sentence_embedding, torch.tensor([prompt_to_id[row.prompt]])))\n",
    "    \n",
    "    # save the embedding\n",
    "    torch.save(sentence_embedding_with_label, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path):\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "    for file in tqdm(os.listdir(path)):\n",
    "        embedding_with_label = torch.load(os.path.join(path, file))\n",
    "        embedding = embedding_with_label[:-1]\n",
    "        label = embedding_with_label[-1]\n",
    "        embeddings_list.append(embedding)\n",
    "        labels_list.append(label)\n",
    "    return torch.stack(embeddings_list), torch.stack(labels_list)\n",
    "\n",
    "train_embeddings, train_labels = load_embeddings(os.path.join(save_path_embedd, \"train\"))\n",
    "valid_embeddings, valid_labels = load_embeddings(os.path.join(save_path_embedd, \"validate\"))\n",
    "test_embeddings, test_labels = load_embeddings(os.path.join(save_path_embedd, \"test\"))\n",
    "print(\"Train embeddings shape: \", train_embeddings.shape, \"Train labels shape: \", train_labels.shape)\n",
    "print(\"Valid embeddings shape: \", valid_embeddings.shape, \"Valid labels shape: \", valid_labels.shape)\n",
    "print(\"Test embeddings shape: \", test_embeddings.shape, \"Test labels shape: \", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "classifier = Classifier(train_embeddings.shape[1], len(prompt_to_id)).to(device)\t\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5000\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "# !! NOTE : use the validation and train set to evaluate the model\n",
    "valid_embeddings = torch.cat((valid_embeddings, train_embeddings))\n",
    "valid_labels = torch.cat((valid_labels, train_labels))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    classifier.train()\n",
    "    # !! NOTE: In this case, we use the test set as training set since it is bigger  \n",
    "    inputs, targets = test_embeddings.to(device), test_labels.to(device, dtype=torch.long)\n",
    "    outputs = classifier(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss = loss.item()\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs, targets = valid_embeddings.to(device), valid_labels.to(device, dtype=torch.long)\n",
    "        outputs = classifier(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        valid_loss = loss.item()\n",
    "        valid_losses.append(valid_loss)\n",
    "        accuracy = torch.mean((torch.argmax(outputs, dim=1) == targets).float())\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"Epoch:\", \"%04d\" % (epoch + 1), \"train cost =\", \"{:.6f}\".format(train_loss), \"valid cost =\", \"{:.6f}\".format(valid_loss), \"valid accuracy =\", \"{:.2f}\".format(accuracy * 100.0))\n",
    "\n",
    "# Plot the train and validation losses\n",
    "plt.plot(train_losses, label='Train loss')\n",
    "plt.plot(valid_losses, label='Valid loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix for the valid set\n",
    "classifier.eval()\n",
    "with torch.no_grad():\n",
    "    inputs, targets = valid_embeddings.to(device), valid_labels.to(device, dtype=torch.long)\n",
    "    outputs = classifier(inputs)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    accuracy = torch.mean((predictions == targets).float())\n",
    "    print(\"Test accuracy: \", accuracy.item())\n",
    "\n",
    "    # Create confusion matrix\n",
    "    confusion_matrix = torch.zeros(len(prompt_to_id), len(prompt_to_id))\n",
    "    for t, p in zip(targets, predictions):\n",
    "        confusion_matrix[t, p] += 1\n",
    "\n",
    "    # Normalize confusion matrix\n",
    "    confusion_matrix = confusion_matrix / confusion_matrix.sum(dim=1, keepdim=True)\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    # Show confusion matrix\n",
    "    plt.imshow(confusion_matrix, cmap='Blues')\n",
    "    plt.xticks(range(len(prompt_to_id)), prompt_to_id.keys(), rotation=90)\n",
    "    plt.yticks(range(len(prompt_to_id)), prompt_to_id.keys())\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Add text annotations for non-zero misclassified data\n",
    "    for i in range(len(prompt_to_id)):\n",
    "        for j in range(len(prompt_to_id)):\n",
    "            value = confusion_matrix[i, j]\n",
    "            if value != 0:\n",
    "                text = plt.text(j, i, f'{value:.2f}', ha='center', va='center', color='green')\n",
    "                # Highlight misclassified data\n",
    "                if i != j:\n",
    "                    text.set_color(\"red\")\n",
    "                    text.set_weight('bold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model using sentences generated by ChatGPT\n",
    "sentences = [\"My back hurts\"]\n",
    "acc = 0 \n",
    "labels = prompt_to_id.values()\n",
    "for sentence, label in zip(sentences, labels):\n",
    "    tokenized_text = tokenizer.tokenize(sentence)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    model.eval()\n",
    "    # Get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "\n",
    "    # take the mean of the embeddings over the whole sentence\n",
    "    sentence_embedding = torch.mean(hidden_states[0], dim=0)\n",
    "\n",
    "    # classify the sentence\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = sentence_embedding.to(device)\n",
    "        inputs = inputs.unsqueeze(0)\n",
    "        outputs = classifier(inputs)\n",
    "        prediction = torch.argmax(outputs, dim=1)\n",
    "        predicted_prompt = list(prompt_to_id.keys())[prediction.item()]\n",
    "     \n",
    "    # print(\"Label: \", label)\n",
    "    print(\"Predicted prompt: \", predicted_prompt)\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"\\n\")\n",
    "    # acc += label == predicted_prompt\n",
    "    \n",
    "# print(\"Accuracy: \", acc / len(sentences), \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare both \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a combination of both\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
